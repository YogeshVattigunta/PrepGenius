{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpQ9WXD9q3fqWEemhdqIRt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YogeshVattigunta/PrepGenius/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q PyPDF2 pdf2image easyocr\n",
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZAYSead35TK",
        "outputId": "81614385-0772-4d5d-e692-3a0f941edab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m2.2/2.9 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m2.3/2.9 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m2.5/2.9 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m2.7/2.9 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/422.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from IPython.display import clear_output, Markdown\n",
        "import PyPDF2\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import easyocr\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyCWzhzAqcvNgvR-qjtfhkewH6IcgxFxx7g\")\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        extracted_text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                extracted_text += text\n",
        "        return extracted_text\n",
        "\n",
        "def questionor(notes, question_generator):\n",
        "    question_generator = f\"\"\"\n",
        "        You're a question-generating assistant.\n",
        "\n",
        "        Steps:\n",
        "        1. Analyze all the uploaded files.\n",
        "        2. Understand the materials.\n",
        "        3. Build 2 MCQ questions based on the materials\n",
        "        3. Build 2 subjective questions based on the materials.\n",
        "        4. Shuffle the questions, number them (e.g., Question 1:...), and\n",
        "        5. separate each of the questions using <q> seprator.\n",
        "        5. Output only the questions.\n",
        "\n",
        "        Note: No markdown elements.\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
        "\n",
        "    material = extract_text_from_pdf(notes)\n",
        "\n",
        "    questions = model.generate_content([question_generator, material]).text\n",
        "\n",
        "    return questions.split(\"<q>\")\n",
        "\n",
        "def answers_sheet(questions, filename = \"answer_sheet.txt\"):\n",
        "    answers = []\n",
        "\n",
        "    for question in questions:\n",
        "        print(question)\n",
        "        answer = input(\"Answer: \")\n",
        "        answers.append((f\"Question : {question.strip()}\", f\"Answer : {answer.strip()}\"))\n",
        "\n",
        "    # Create a .txt file with the Q&A format\n",
        "    with open(filename, \"w\") as file:\n",
        "        for question, answer in answers:\n",
        "            file.write(f\"{question}\\n{answer}\\n\\n\")\n",
        "\n",
        "\n",
        "def evaluator(answer_paper):\n",
        "\n",
        "    evaluator = \"\"\"\n",
        "        Your are an evaluation assistant where:\n",
        "\n",
        "        1. You get the answer sheet provided by the user.\n",
        "        2. You check Answers corresponding to the question.\n",
        "        3. Then, evaluate the answers with questions.\n",
        "        4. And add evaluation as : correct, worng\n",
        "        5. The evaluation will be displayed as, evaluation: correct\n",
        "        6. The convert the evaluation score into percentage and display it at the end as \"Total score : \"\n",
        "        7. The you will add a unique seprator <evl> between the last question and Total score\n",
        "\n",
        "        example:\n",
        "            Question 1: What is the capital of France?\n",
        "            Answer 1: Paris\n",
        "            Evaluation 1: correct\n",
        "            Question 2: What is the largest planet in our solar system?\n",
        "            Answer 2: Sun\n",
        "            Evaluation 2: wrong\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    answer_sheet = genai.upload_file(answer_paper)\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
        "    evaluation = model.generate_content([evaluator, answer_sheet]).text\n",
        "\n",
        "    final_score = evaluation.split(\"<evl>\")[-1]\n",
        "    print(final_score)\n",
        "    print()\n",
        "    time_limit = input(\"Time left for Exam: \")\n",
        "\n",
        "\n",
        "reader = easyocr.Reader(['en'])  # Add other languages if needed\n",
        "\n",
        "def pdf_image_processor(pdf_path, output_path:str=\"previous year question paper.txt\"):\n",
        "    images = convert_from_path(pdf_path)\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        print(f\"Processing page {i + 1}...\")\n",
        "        # Convert PIL Image to NumPy array\n",
        "        img_np = np.array(img)\n",
        "        ocr_result = reader.readtext(img_np)  # Pass NumPy array to readtext\n",
        "        page_text = \"\\n\".join([text[1] for text in ocr_result])\n",
        "        extracted_text += f\"Page {i + 1}:\\n{page_text}\\n\\n\"\n",
        "\n",
        "    return extracted_text\n",
        "\n",
        "\n",
        "def important_topic_generator(pyq, notes, finial_score, time_left_for_exam):\n",
        "    topics_template = f\"\"\"\n",
        "\n",
        "        Your are a content generating assistant which tells user important topics to be covered within the time limit.\n",
        "\n",
        "        Steps:\n",
        "        1. You collects the study materials uploaded by the user: {notes}.\n",
        "        2. You get the final socre of the quiz: {final_score}.\n",
        "        3. You also collects previous year question paper: {pyq}.\n",
        "        4. Then, analyze the question paper and the materials.\n",
        "        5. After that you build most import topics to be covered within the time limit: {time_left_for_exam}\n",
        "        6. Then, the questions are displayed in plain form.\n",
        "\n",
        "\n",
        "        Note: don't display unnecessary text\n",
        "        Note: no need of examples\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\n",
        "        model_name = \"gemini-1.5-pro\",\n",
        "        system_instruction=topics_template\n",
        "\n",
        "    )\n",
        "\n",
        "    response = model.generate_content(topics_template).text\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "gWYMuBkMZNJX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}